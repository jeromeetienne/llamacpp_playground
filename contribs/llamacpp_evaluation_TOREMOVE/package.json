{
  "name": "llama_cpp_evaluation",
  "version": "1.0.0",
  "description": "## Goals - [ ] Compare the performance of llamacpp models - [ ] do it with 2 technologies: natively node-llama-cpp and langchain.js   - langchain.js support for llamacpp is not perfect - [ ] What are the limits of langchain.js's support for llamacpp",
  "main": "index.js",
  "type": "module",
  "bin": {
    "llama_cpp_evaluation": "bin/llama_cpp_evaluation.js"
  },
  "scripts": {
    "evaluation": "node ./bin/llama_cpp_evaluation.js",
    "generate":"node ./bin/llama_cpp_evaluation.js generate myEval",
    "predict":"node ./bin/llama_cpp_evaluation.js predict myEval myPredict",
    "evaluate":"node ./bin/llama_cpp_evaluation.js evaluate myEval myPredict",
    "report":"node ./bin/llama_cpp_evaluation.js report myEval",
    "hptuning":"node ./bin/llama_cpp_evaluation.js hptuning myEval ./data/evaluations/hptunings/superHpTuning.hptuning.json5",
    "test": "cd test && npm test"
  },
  "keywords": [],
  "author": "",
  "license": "ISC"
}
